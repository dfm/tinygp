{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e39d4c-9caf-4435-a8ed-aba9544bdfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tinygp\n",
    "except ImportError:\n",
    "    %pip install -q tinygp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d8253c-8c31-49be-b7d0-ead5b1dccfb5",
   "metadata": {},
   "source": [
    "(multivariate)=\n",
    "\n",
    "# Multivariate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783fc2f1-2359-4f69-bdac-28baad1d86be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random = np.random.default_rng(48392)\n",
    "X = random.uniform(-5, 5, (100, 2))\n",
    "yerr = 0.1\n",
    "y = np.sin(X[:, 0]) * np.cos(X[:, 1] + X[:, 0]) + yerr * random.normal(size=len(X))\n",
    "\n",
    "# For plotting predictions on a grid\n",
    "x_grid, y_grid = np.linspace(-5, 5, 100), np.linspace(-5, 5, 50)\n",
    "x_, y_ = np.meshgrid(x_grid, y_grid)\n",
    "y_true = np.sin(x_) * np.cos(x_ + y_)\n",
    "X_pred = np.vstack((x_.flatten(), y_.flatten())).T\n",
    "\n",
    "# For plotting covariance ellipses\n",
    "theta = np.linspace(0, 2*np.pi, 500)[None, :]\n",
    "elipse = 0.5 * np.concatenate((np.cos(theta), np.sin(theta)), axis=0)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pcolor(x_grid, y_grid, y_true, vmin=y_true.min(), vmax=y_true.max())\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, ec=\"black\", vmin=y_true.min(), vmax=y_true.max())\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "_ = plt.title(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae53528-5d8f-4ae5-bf44-69abf7773a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from scipy.optimize import minimize\n",
    "from tinygp import GaussianProcess, kernels, transforms\n",
    "\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "def train_gp(nparams, build_gp_func):\n",
    "    @jax.jit\n",
    "    @jax.value_and_grad\n",
    "    def loss(params):\n",
    "        return -build_gp_func(params).condition(y)\n",
    "    \n",
    "    params = np.zeros(nparams)\n",
    "    soln = minimize(loss, params, jac=True)\n",
    "    return build_gp_func(soln.x)\n",
    "\n",
    "def build_gp_uncorr(params):\n",
    "    kernel = jnp.exp(params[0]) * kernels.ExpSquared(jnp.exp(params[1:3]))\n",
    "    return GaussianProcess(kernel, X, diag=yerr ** 2)\n",
    "\n",
    "uncorr_gp = train_gp(3, build_gp_uncorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f564506e-7de3-431b-81c3-868e5c04c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = uncorr_gp.predict(y, X_pred).reshape(y_true.shape)\n",
    "xy = uncorr_gp.kernel.kernel2.scale[:, None] * elipse\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6), sharex=True, sharey=True)\n",
    "axes[0].plot(xy[0], xy[1], \"--k\", lw=0.5)\n",
    "axes[0].pcolor(x_, y_, y_pred, vmin=y_true.min(), vmax=y_true.max())\n",
    "axes[0].scatter(X[:, 0], X[:, 1], c=y, ec=\"black\", vmin=y_true.min(), vmax=y_true.max())\n",
    "axes[1].pcolor(x_, y_, y_pred - y_true, vmin=y_true.min(), vmax=y_true.max())\n",
    "axes[0].set_xlabel(\"x\")\n",
    "axes[0].set_ylabel(\"y\")\n",
    "axes[0].set_title(\"uncorrelated kernel\")\n",
    "axes[1].set_xlabel(\"x\")\n",
    "_ = axes[1].set_title(\"residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f017c3f0-9951-48b1-97e3-019aa5096a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gp_corr(params):    \n",
    "    # Build the lower triangular matrix giving the input parameter covariance\n",
    "    factor = jnp.zeros((2, 2))\n",
    "    factor = factor.at[jnp.diag_indices(2)].add(jnp.exp(params[1:3]))\n",
    "    factor = factor.at[jnp.tril_indices(2, -1)].add(params[3:])\n",
    "    \n",
    "    kernel = jnp.exp(params[0]) * transforms.Affine(factor, kernels.ExpSquared())\n",
    "    return GaussianProcess(kernel, X, diag=yerr ** 2)\n",
    "\n",
    "corr_gp = train_gp(4, build_gp_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087ac75c-e7d9-4055-bada-85971bcf2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = corr_gp.predict(y, X_pred).reshape(y_true.shape)\n",
    "xy = corr_gp.kernel.kernel2.scale @ elipse\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6), sharex=True, sharey=True)\n",
    "axes[0].plot(xy[0], xy[1], \"--k\", lw=0.5)\n",
    "axes[0].pcolor(x_, y_, y_pred, vmin=y_true.min(), vmax=y_true.max())\n",
    "axes[0].scatter(X[:, 0], X[:, 1], c=y, ec=\"black\", vmin=y_true.min(), vmax=y_true.max())\n",
    "axes[1].pcolor(x_, y_, y_pred - y_true, vmin=y_true.min(), vmax=y_true.max())\n",
    "axes[0].set_xlabel(\"x\")\n",
    "axes[0].set_ylabel(\"y\")\n",
    "axes[0].set_title(\"correlated kernel\")\n",
    "axes[1].set_xlabel(\"x\")\n",
    "_ = axes[1].set_title(\"residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98bab1c-2a77-4f0d-8e87-1ff7a01bce06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
