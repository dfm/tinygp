{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import tinygp\n",
    "except ImportError:\n",
    "    %pip install -q tinygp\n",
    "\n",
    "try:\n",
    "    import george\n",
    "except ImportError:\n",
    "    %pip install -q george\n",
    "\n",
    "try:\n",
    "    import celerite2\n",
    "except ImportError:\n",
    "    %pip install -q celerite2\n",
    "\n",
    "from jax.config import config\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(benchmarks)=\n",
    "\n",
    "# Benchmarks\n",
    "\n",
    "One of the `tinygp` design decisions was to provide a high-level API similar to the one provided by the [george](https://george.readthedocs.io) GP library.\n",
    "This was partly because I (as the lead developer of `george`) wanted to ease users' transitions away from `george` to something more modern (like `tinygp`).\n",
    "I also quite like the `george` API and don't think that there exist other similar tools.\n",
    "The defining feature is `tinygp` does not include built-in implementations of inference algorithms.\n",
    "Instead, it provides an expressive model-building interface that makes it easy to experiment with different kernels while still integrating with your favorite inference engine.\n",
    "\n",
    "In this document, we compare the interface and computational performance of `tinygp` with [george](https://george.readthedocs.io) and [celerite2](https://celerite2.readthedocs.io) for constructing kernel models and evaluating the GP marginalized likelihood.\n",
    "Since `tinygp` supports GPU-acceleration, we have executed this notebook on a machine with the following GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi --query-gpu=gpu_name --format=csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the CPU versions of all of these libraries will use parallel linear algebra to take advantage of multiple CPU threads, however to make the benchmarks more replicable, we'll disable this parallelization for the remainder of this notebook.\n",
    "We're also explicitly enabling `jax`'s support for double precision calculations, since the other libraries typically operate at double precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"JAX_ENABLE_X64\"] = \"True\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"XLA_FLAGS\"] = (\n",
    "    os.environ.get(\"XLA_FLAGS\", \"\")\n",
    "    + \" --xla_cpu_multi_thread_eigen=false intra_op_parallelism_threads=1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this benchmark, we'll compare the cost of computing the marginalized likelihood for a GP model using the following methods from other packages:\n",
    "\n",
    "1. As a baseline, we'll run the default `george` solver, that uses `numpy` for linear algebra. This method scales as approximately $\\mathcal{O}(N^3)$.\n",
    "2. We also benchmark the HODLR solver implemented in `george`, which is an _approximate_ solver for black-box kernel models that scales asymptotically as $\\mathcal{O}(N\\log^2 N)$.\n",
    "3. Finally, we run the `celerite2` implementation of the [celerite algorithm](https://arxiv.org/abs/1703.09710), which scales linearly with the size of the dataset, but it can only be used for datasets and models with restricted properties.\n",
    "\n",
    "Then we compare these results to the runtime for the following implementations from `tinygp`:\n",
    "\n",
    "1. The default solver, run on the CPU. This should have similar runtime and scaling as the `george` baseline from above.\n",
    "2. The default solver, run on the GPU. This will have the same asymptotic scaling, but can be much faster than the CPU version for moderately large problems.\n",
    "3. A scalable solver using \"quasiseparable\" structured matrices, much like the `celerite2` comparison above. This will have similar performance as `celerite2`, but suffer from the same restrictions on the kernel and dataset.\n",
    "\n",
    "The syntax of these functions is quite similar, but there are a few differences.\n",
    "Most notably, comparing the `george` and `tinygp` implementations, the units of the \"metric\" or \"length scale\" parameter in the kernel is different (length-squared in `george` and not squared in `tinygp`), and the `gp.compute` method no longer exists in `tinygp` since this would be less compatible with `jax`'s preference for pure functional programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jax\n",
    "\n",
    "import george\n",
    "import celerite2\n",
    "import tinygp\n",
    "\n",
    "sigma = 1.5\n",
    "rho = 2.5\n",
    "jitter = 0.1\n",
    "\n",
    "random = np.random.default_rng(49382)\n",
    "x = np.sort(random.uniform(0, 10, 100_000))\n",
    "y = np.sin(x) + jitter * random.normal(0, 1, len(x))\n",
    "\n",
    "\n",
    "def george_loglike(x, y, **kwargs):\n",
    "    kernel = sigma**2 * george.kernels.Matern32Kernel(rho**2)\n",
    "    gp = george.GP(kernel, **kwargs)\n",
    "    gp.compute(x, jitter)\n",
    "    return gp.log_likelihood(y)\n",
    "\n",
    "\n",
    "hodlr_loglike = partial(\n",
    "    george_loglike, solver=george.solvers.HODLRSolver, tol=0.5\n",
    ")\n",
    "\n",
    "\n",
    "def celerite_loglike(x, y):\n",
    "    kernel = celerite2.terms.Matern32Term(sigma=sigma, rho=rho)\n",
    "    gp = celerite2.GaussianProcess(kernel, x, diag=jitter**2)\n",
    "    return gp.log_likelihood(y)\n",
    "\n",
    "\n",
    "def tinygp_loglike(x, y):\n",
    "    kernel = sigma**2 * tinygp.kernels.Matern32(rho)\n",
    "    gp = tinygp.GaussianProcess(kernel, x, diag=jitter**2)\n",
    "    return gp.log_probability(y)\n",
    "\n",
    "\n",
    "tinygp_loglike_cpu = jax.jit(tinygp_loglike, backend=\"cpu\")\n",
    "tinygp_loglike_gpu = jax.jit(tinygp_loglike, backend=\"gpu\")\n",
    "\n",
    "\n",
    "@partial(jax.jit, backend=\"cpu\")\n",
    "def quasisep_loglike(x, y):\n",
    "    kernel = tinygp.solvers.quasisep.kernels.Matern32(sigma=sigma, scale=rho)\n",
    "    gp = tinygp.GaussianProcess(kernel, x, diag=jitter**2)\n",
    "    return gp.log_probability(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we benchmark the computational cost of computing the log likelihood using each of these methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [10, 20, 100, 200, 1_000, 2_000, 10_000, 20_000, len(x)]\n",
    "george_time = []\n",
    "hodlr_time = []\n",
    "cpu_time = []\n",
    "gpu_time = []\n",
    "quasisep_time = []\n",
    "celerite_time = []\n",
    "for n in ns:\n",
    "    print(f\"\\nN = {n}:\")\n",
    "\n",
    "    args = x[:n], y[:n]\n",
    "    gpu_args = jax.device_put(x[:n]), jax.device_put(y[:n])\n",
    "\n",
    "    if n < 10_000:\n",
    "        results = %timeit -o george_loglike(*args)\n",
    "        george_time.append(results.average)\n",
    "\n",
    "        tinygp_loglike_cpu(*args).block_until_ready()\n",
    "        results = %timeit -o tinygp_loglike_cpu(*args).block_until_ready()\n",
    "        cpu_time.append(results.average)\n",
    "\n",
    "    if n <= 20_000:\n",
    "        results = %timeit -o hodlr_loglike(*args)\n",
    "        hodlr_time.append(results.average)\n",
    "\n",
    "        tinygp_loglike_gpu(*gpu_args).block_until_ready()\n",
    "        results = %timeit -o tinygp_loglike_gpu(*gpu_args).block_until_ready()\n",
    "        gpu_time.append(results.average)\n",
    "\n",
    "    results = %timeit -o quasisep_loglike(*args)\n",
    "    quasisep_time.append(results.average)\n",
    "\n",
    "    results = %timeit -o celerite_loglike(*args)\n",
    "    celerite_time.append(results.average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot of this benchmark, you'll notice several features:\n",
    "\n",
    "1. For very small datasets, the `tinygp` CPU implementations are significantly faster than any of the other implementations. This is because `jax.jit` removes a lot of the Python overhead that is encountered when chaining `numpy` functions.\n",
    "2. For medium to large datasets, `tinygp` is generally faster than `george`, with the GPU version seeing a significant advantage.\n",
    "3. The CPU implementations approach the expected asymptotic complexity of $\\mathcal{O}(N^3)$ only for the largest values of $N$. This is probably caused by memory allocation overhead or other operations with better scaling than the Cholesky factorization.\n",
    "4. The approximate \"HODLR\" solver from `george` outperforms the GPU-enabled `tinygp` exact solver, but only for very large datasets, and it's important to note that the HODLR method does not scale well to larger input dimensions. Any existing or future approximate solvers like this that are implemented in `jax` could be easily used in conjunction with `tinygp`, but such things have not yet been implemented.\n",
    "5. The `celerite2` and `tinygp` structured kernel implementation have nearly identical performance for large systems, but the `tinygp` implementation is significantly faster for small systems (despite being implemented in high-level `jax`, whereas `celerite2` is mostly written in C++)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(\n",
    "    ns[: len(george_time)],\n",
    "    george_time,\n",
    "    \"o-\",\n",
    "    color=\"k\",\n",
    "    lw=0.75,\n",
    "    label=\"george (exact)\",\n",
    ")\n",
    "plt.loglog(\n",
    "    ns[: len(hodlr_time)],\n",
    "    hodlr_time,\n",
    "    \"s:\",\n",
    "    color=\"k\",\n",
    "    lw=1,\n",
    "    label=\"george (approx)\",\n",
    ")\n",
    "plt.loglog(\n",
    "    ns, celerite_time, \"^--\", color=\"k\", lw=0.75, label=\"celerite2 (struct)\"\n",
    ")\n",
    "\n",
    "plt.loglog(\n",
    "    ns[: len(cpu_time)],\n",
    "    cpu_time,\n",
    "    \"o-\",\n",
    "    color=\"C0\",\n",
    "    lw=2,\n",
    "    label=\"tinygp (exact; CPU)\",\n",
    ")\n",
    "plt.loglog(\n",
    "    ns[: len(gpu_time)],\n",
    "    gpu_time,\n",
    "    \"o-\",\n",
    "    color=\"C1\",\n",
    "    lw=2,\n",
    "    label=\"tinygp (exact; GPU)\",\n",
    ")\n",
    "plt.loglog(\n",
    "    ns, quasisep_time, \"^--\", color=\"C2\", lw=2, label=\"tinygp (struct; CPU)\"\n",
    ")\n",
    "\n",
    "plt.legend(fontsize=10)\n",
    "plt.xlabel(\"number of data points\")\n",
    "plt.ylabel(\"runtime [s]\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinygp-venv",
   "language": "python",
   "name": "tinygp-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
